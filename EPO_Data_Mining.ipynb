{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOflWtimpwmpL3JVYvS7MB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarvisx17/EPO/blob/main/EPO_Data_Mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_pMeCtbVuwwR"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/gsong/python-epo-ops-client\n",
        "!pip install xmltodict\n",
        "!pip install python-epo-ops-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import epo_ops\n",
        "import json\n",
        "import xmltodict\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import pprint\n",
        "# from pymongo import MongoClient"
      ],
      "metadata": {
        "id": "wNmoilbiu7bk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module_path = os.path.abspath(os.path.join('python-epo-ops-client')) # or the path to your source code\n",
        "sys.path.insert(0, module_path)"
      ],
      "metadata": {
        "id": "JK5_10opvI6G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~ Initialize API client for EPO patents ~ #\n",
        "client = epo_ops.Client(key='wuv2ZOHumPKd7D3FEHVeQeSM819eIWry', secret='iJTsADGX2AAc5pWq')  # Instantiate client"
      ],
      "metadata": {
        "id": "f25cMwINvLHX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Date Range of Documents to be retrive\n",
        "response = client.register_search(\"pd=20211108-20211213 and classification=g\", range_begin=1, range_end=100) \n",
        "# print(len(response.text))\n",
        "data_dict = xmltodict.parse(response.text)\n",
        "json_data = json.dumps(data_dict)\n",
        "# print(json_data[:1000])"
      ],
      "metadata": {
        "id": "kGO4XQxVvLvz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_patents = []\n",
        "list_of_epodoc_objects = []\n",
        "array_of_patents = (data_dict[\"ops:world-patent-data\"][\"ops:register-search\"][\"reg:register-documents\"][\"reg:register-document\"])\n",
        "\n",
        "for patent in array_of_patents:\n",
        "#     print(patent['reg:bibliographic-data'][\"reg:invention-title\"])\n",
        "#     print(patent['reg:bibliographic-data'][\"reg:publication-reference\"][\"reg:document-id\"])\n",
        "    patent_number = str(patent['reg:bibliographic-data'][\"reg:publication-reference\"][\"reg:document-id\"]\n",
        "         ['reg:country']+patent['reg:bibliographic-data'][\"reg:publication-reference\"]\n",
        "          [\"reg:document-id\"][\"reg:doc-number\"]\n",
        "         )\n",
        "    list_of_patents.append(patent_number)\n",
        "    list_of_epodoc_objects.append(epo_ops.models.Epodoc(patent_number))\n",
        "#     print(patent['reg:bibliographic-data'][\"reg:classifications-ipcr\"][\"reg:classification-ipcr\"])"
      ],
      "metadata": {
        "id": "fdagKO1SvPn5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# patents = [epo_ops.models.Epodoc(\"EP3920660\"), epo_ops.models.Epodoc(\"EP3918902\")]\n",
        "api_response = client.published_data(  # Retrieve bibliography data\n",
        "  reference_type = 'publication',  # publication, application, priority\n",
        "  input = list_of_epodoc_objects,  # can be a list of original, docdb, epodoc\n",
        "  endpoint = 'biblio',  # optional, defaults to biblio in case of published_data\n",
        "  constituents = []  # optional, list of constituents\n",
        ")\n",
        "\n",
        "# this produces a python list with an entry for each patent\n",
        "response_list=xmltodict.parse(api_response.text)[\"ops:world-patent-data\"]['exchange-documents']['exchange-document']\n",
        "#optional: override list by cutting down for shorter testing\n",
        "# response_list=response_list[:10]\n",
        "# print(len(response_list))\n",
        "# print(json.dumps(response_list, indent = 4)[:50000])"
      ],
      "metadata": {
        "id": "uqEvGnHxvs25"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getFullText(epodoc):\n",
        "    # trying with a recently published EPO numbered doc works\n",
        "    ft_response = client.published_data(  # Retrieve bibliography data\n",
        "      reference_type = 'publication',  # publication, application, priority\n",
        "      input = epo_ops.models.Epodoc(epodoc),  # original, docdb, epodoc\n",
        "      endpoint = 'description',  # fulltext lists what is available (claims, description, both)\n",
        "      constituents = []  \n",
        "    )\n",
        "    return xmltodict.parse(ft_response.text)\n",
        "\n",
        "def getParagraph(fullText, para):\n",
        "  if isinstance(para, int):\n",
        "      para=f\"[{para:04d}]\"\n",
        "      # print(para)\n",
        "  response = {}\n",
        "  para_list = fullText[\"description\"][\"p\"]\n",
        "  for paragraph in para_list:\n",
        "      if para in paragraph:\n",
        "          response[para] = paragraph\n",
        "  return response\n",
        "\n",
        "\n",
        "def getCitedParagraphs(citation):\n",
        "    # print(\"\\noriginal citation: \", citation)############################################################################################################\n",
        "    citedParagraphs = []\n",
        "    if type(citation) == list:\n",
        "        if len(citation) == 1:\n",
        "            return getCitedParagraphs(citation[0])\n",
        "        # clean up each element of the list\n",
        "        for part in citation:\n",
        "            citedParagraphs = citedParagraphs + cleanup(part)\n",
        "    else:\n",
        "        citationList=re.split(\",|;\", citation)\n",
        "        for part in citationList:\n",
        "            citedParagraphs = citedParagraphs + cleanup(part)\n",
        "    # print(\"citedParagraphs intermediate: \", citedParagraphs)############################################################################################################\n",
        "    for passage in citedParagraphs:\n",
        "        if (re.search(r\"(?i)fig\\S*|columns?|abstract\", passage)) or not (re.findall(r\"\\d\", passage)):\n",
        "            citedParagraphs.remove(passage)\n",
        "            # print(f\"removed %s from paragraph list\" % passage)\n",
        "            continue\n",
        "        references = re.findall(r\"\\[\\d+\\]\", passage)\n",
        "        if len(references) > 2: # some citations are messed up in API version, this splits back into pairs\n",
        "            citedParagraphs.remove(passage)\n",
        "            for i in range(0, len(references)-1, 2):\n",
        "                citedParagraphs.append(re.sub(r\"\\[|\\]\", \"\", references[i]+\"-\"+references[i+1]))\n",
        "            if len(references)%2 == 1:\n",
        "                citedParagraphs.append(re.sub(r\"\\[|\\]\", \"\", references[-1])) # final element\n",
        "    citedParagraphs = [re.sub(r\"\\[|\\]\", \"\", item) for item in citedParagraphs] # remove remaining square brackets\n",
        "    \n",
        "    # print(\"citedParagraphs: \", citedParagraphs)\n",
        "    return citedParagraphs\n",
        "\n",
        "def cleanup(paraString):\n",
        "    clean = []\n",
        "    splitString = re.split(\",|;\", paraString)\n",
        "    for para in splitString:\n",
        "        # ignore elements that are not paragraphs (or just numbers which represent paragraphs)\n",
        "        # (?i) makes it case insensitive\n",
        "        if not(re.search(r\"(?i)fig\\S*|columns?|abstract\", para)):\n",
        "            # remove stars, paragraphs, whitespace\n",
        "            cleanedup = re.sub(r\"\\*|paragraphs?|\\s|;.*$\", \"\", para)\n",
        "            if (re.search(r\"\\[\\d*\\]\", cleanedup)): # must contain a number between square brackets\n",
        "                clean.append(cleanedup)\n",
        "    return clean\n",
        "\n",
        "def getClaims(epodoc):\n",
        "    api_response = client.published_data(  # Retrieve bibliography data\n",
        "        reference_type='publication',  # publication, application, priority\n",
        "        input = epo_ops.models.Epodoc(epodoc),  # original, docdb, epodoc\n",
        "        endpoint='claims',  \n",
        "        constituents=[]  # optional, list of constituents\n",
        "    )\n",
        "    json_response = xmltodict.parse(api_response.text)\n",
        "    return (json_response['ops:world-patent-data']['ftxt:fulltext-documents']['ftxt:fulltext-document']\n",
        "        ['claims']['claim']['claim-text'])\n",
        "\n",
        "def getRangeFromString(rangeString):\n",
        "    rangeList = []\n",
        "    if '-' in rangeString:\n",
        "        itemRange = rangeString.split(\"-\")\n",
        "        rangeList = (list(range(int(itemRange[0]), int(itemRange[-1]) + 1)))\n",
        "    else:\n",
        "        rangeList.append(int(rangeString))\n",
        "    return rangeList\n",
        "\n",
        "def checkAndDownloadClaims(response):\n",
        "    # print(response[\"bibliographic-data\"].keys())\n",
        "    if not (\"claims\" in response[\"bibliographic-data\"].keys()):\n",
        "        response[\"bibliographic-data\"][\"claims\"] = (getClaims(\n",
        "                response[\"bibliographic-data\"][\"publication-reference\"][\"document-id\"][1][\"doc-number\"]))\n",
        "            # print(json.dumps(response[\"bibliographic-data\"], indent=4))\n",
        "        # print(response[\"bibliographic-data\"].keys())"
      ],
      "metadata": {
        "id": "12NuRci_v5sx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is currently the \"main loop\" that pulls citations for each\n",
        "# patent in turn, then gets the full text of patents cited (if available)\n",
        "# and the claims against which each was cited\n",
        "\n",
        "count = 0\n",
        "cit = 0\n",
        "xcit = 0\n",
        "ftxcit = 0\n",
        "dlclaims = 0\n",
        "text = ''\n",
        "rel_patent = ''\n",
        "text_2 = []\n",
        "claims_list = []\n",
        "category = []\n",
        "rel_cat_claims = []\n",
        "citations_dataset = [] #  this list will hold the patents where all necessary info has been downloaded\n",
        "\n",
        "for response in response_list:\n",
        "    count += 1\n",
        "    # print(\"\\n\", \"Count: \", count)\n",
        "    Patent_Nuumber_d = json.dumps(response[\"bibliographic-data\"][\"publication-reference\"]['document-id'][1]['doc-number'])\n",
        "    # print(\"Patent No.: \", json.dumps(response[\"bibliographic-data\"][\"publication-reference\"]['document-id'][1]['doc-number']))\n",
        "    #print(getClaims(response[\"bibliographic-data\"][\"publication-reference\"][\"document-id\"][1][\"doc-number\"]))\n",
        "    if \"references-cited\" in response[\"bibliographic-data\"]:\n",
        "        listofcitations = response[\"bibliographic-data\"][\"references-cited\"][\"citation\"]\n",
        "        if isinstance(listofcitations, dict): # catches the case of a single citation, returned as a dict\n",
        "            listofcitations = [listofcitations]\n",
        "        # print(\"Number of citations: \", len(listofcitations))\n",
        "        cit += len(listofcitations)\n",
        "        # print(listofcitations) # avoid unless troubleshooting\n",
        "        # citations by applicant do not have category etc... -> check examiner citation\n",
        "        download_claims = False\n",
        "        for citation in listofcitations:\n",
        "            if (citation[\"@cited-by\"]==\"examiner\" and \"X\" in citation[\"category\"] and \"patcit\" in citation): # consider looking at publications later \"nplcit\"\n",
        "                xcit += 1\n",
        "                # print(\"Citation details: \", citation[\"@sequence\"], citation[\"category\"], \n",
        "                      # citation[\"rel-claims\"], \"Cited doc: \", json.dumps(citation[\"patcit\"][\"document-id\"][0]))\n",
        "                \n",
        "                patent_number = citation[\"patcit\"][\"document-id\"][0][\"doc-number\"]\n",
        "                if patent_number[:2] == \"EP\":\n",
        "                    rel_patent += citation[\"patcit\"][\"document-id\"][0]['doc-number'] + ' '\n",
        "                    checkAndDownloadClaims(response)\n",
        "                    ftxcit += 1\n",
        "                    # print(\"Further processing possible: downloading EP full text\")\n",
        "                    category.append(citation[\"category\"])\n",
        "                    rel_cat_claims.append(citation[\"rel-claims\"])\n",
        "                    citation[\"citation_text\"] = getFullText(patent_number)[\"ops:world-patent-data\"][\"ftxt:fulltext-documents\"][\"ftxt:fulltext-document\"]\n",
        "                    citation[\"rel-passage\"][\"rel-passage-list\"] = getCitedParagraphs(citation[\"rel-passage\"][\"passage\"])\n",
        "                    passageSet = set() # using a set to guarantee uniqueness\n",
        "                    for passages in citation[\"rel-passage\"][\"rel-passage-list\"]:\n",
        "                        passageSet.update(set(getRangeFromString(passages)))\n",
        "                    citation[\"rel-passage\"][\"rel-passage-full-set\"] = sorted(list(passageSet)) # convert back to list as sets can't go in JSON\n",
        "                    # print(citation[\"rel-passage\"][\"rel-passage-full-set\"])\n",
        "                    citation[\"rel-passage\"][\"rel-passage-full-text\"]=[]\n",
        "                    for passage in citation[\"rel-passage\"][\"rel-passage-full-set\"]:\n",
        "                        citation[\"rel-passage\"][\"rel-passage-full-text\"].append(getParagraph(citation[\"citation_text\"], passage))\n",
        "                    text_2.append(citation[\"rel-passage\"][\"rel-passage-full-text\"])\n",
        "                    # print(citation[\"rel-passage\"][\"rel-passage-full-text\"])\n",
        "                    # print(json.dumps(citation, indent=4))\n",
        "                    # turn rel-claims into a list:\n",
        "                    if ',' in citation[\"rel-claims\"]:\n",
        "                        claimsList = []\n",
        "                        for claimItem in citation[\"rel-claims\"].split(\",\"):\n",
        "                            claimsList.extend(getRangeFromString(claimItem))\n",
        "                    else:\n",
        "                        claimsList = [citation[\"rel-claims\"]]\n",
        "                    citation[\"rel-claims-list\"] = claimsList\n",
        "                    # print(\"adding rel-claims-list\", claimsList)\n",
        "                    claims_list.append(claimsList)\n",
        "                    text += Patent_Nuumber_d + ' '\n",
        "\n",
        "        if download_claims is True:\n",
        "            dlclaims += 1\n",
        "            citations_dataset.append(response)"
      ],
      "metadata": {
        "id": "gg2Ew8lYv9Pc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# patent numbers\n",
        "patent_numbers = text.replace('\"','')\n",
        "patent_list = patent_numbers.split(' ')\n",
        "patent_list = patent_list[:-1]\n",
        "\n",
        "# related Patent\n",
        "related_Patent = rel_patent.split(' ')\n",
        "related_Patent = related_Patent[:-1]"
      ],
      "metadata": {
        "id": "UYubnhshwSoh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "claim_list = []\n",
        "for i in patent_list:\n",
        "  x = getClaims(i)\n",
        "  claim_list.append(x)"
      ],
      "metadata": {
        "id": "PoYRcfbwwZjl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EPO Dataframe"
      ],
      "metadata": {
        "id": "OmEgFhl7xyi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'Patent No.': patent_list, \"Cited Patent No.\" : related_Patent, \"Cited Text\" : text_2, \"Claims\" : claim_list, \"Rel-Claims No.\": claims_list, \"Category\" : category, \"cat_claims\" : rel_cat_claims})\n",
        "# df.to_csv('EPO.csv', index=False)"
      ],
      "metadata": {
        "id": "5r7lmIrdw8LR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Negative'] = None\n",
        "df['Positive'] = None"
      ],
      "metadata": {
        "id": "zYXZCJ4-xK_M"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for l in df.index:\n",
        "  xx = df.Category[l]\n",
        "  yy = df.cat_claims[l]\n",
        "  claims = df.Claims[l]\n",
        "\n",
        "  \n",
        "  claimmss = []\n",
        "  rel_claims = []\n",
        "\n",
        "  # def claimscolumn():\n",
        "  if type(xx)==list:\n",
        "    for i in range(len(xx)):\n",
        "      if xx[i] == 'X' or xx[i] == 'I':\n",
        "      # if xx[i] == 'A' or xx[i] == 'Y' :\n",
        "        vv = yy[i]\n",
        "        vv = vv.split(\",\")\n",
        "        for j in vv:\n",
        "          if ('-' in j) == False:\n",
        "            claimmss.append(int(j))\n",
        "            n = int(j)-1\n",
        "            # print(claims[n])\n",
        "            rel_claims.append(claims[n])\n",
        "          if ('-' in j) == True:\n",
        "            cc = j.split(\"-\")\n",
        "            for i in range(int(cc[0]), int(cc[1])+1):\n",
        "              claimmss.append(i)\n",
        "              n = i-1\n",
        "              # print(claims[n])\n",
        "              rel_claims.append(claims[n])\n",
        "          else:\n",
        "            # rel_claims.append('')\n",
        "            pass\n",
        "  else:\n",
        "    if xx == 'X' or xx == 'I':\n",
        "    # if xx == 'A' or  xx == 'Y':\n",
        "      vv = yy\n",
        "      vv = vv.split(\",\")\n",
        "      for j in vv:\n",
        "        if ('-' in j) == False:\n",
        "          claimmss.append(int(j))\n",
        "          n = int(j)-1\n",
        "          # print(claims[n])\n",
        "          rel_claims.append(claims[n])\n",
        "        if ('-' in j) == True:\n",
        "          cc = j.split(\"-\")\n",
        "          for i in range(int(cc[0]), int(cc[1])+1):\n",
        "            claimmss.append(i)\n",
        "            n = i-1\n",
        "            # print(claims[n])\n",
        "            rel_claims.append(claims[n])\n",
        "        else:\n",
        "          # rel_claims.append('')\n",
        "          pass\n",
        "  # df['Negative'][l] = rel_claims\n",
        "  df['Positive'][l] = rel_claims\n",
        "\n",
        "  # print(claimmss)"
      ],
      "metadata": {
        "id": "RRcSrppcxbcf"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df"
      ],
      "metadata": {
        "id": "H_JLZaFQxtor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Negative Dataframe"
      ],
      "metadata": {
        "id": "GDpoPNP0xj1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Negative_df = df[['Cited Text','Negative']]\n",
        "rows = [0,1,3,4,5,7]\n",
        "Negative_df.drop(rows, axis=0, inplace=True)\n",
        "label = ['Negative','Negative']\n",
        "Negative_df['Label'] = label\n",
        "Negative_df = Negative_df.explode('Negative')\n",
        "Negative_df.rename(columns = {'Negative':'rel_Claim'}, inplace = True)\n",
        "Negative_df"
      ],
      "metadata": {
        "id": "VoEEJ-CA1yRB"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Positive Dataframe"
      ],
      "metadata": {
        "id": "J13josX_2GNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Positve_df = df[['Cited Text','Positive']]\n",
        "Positve_df.drop(3, axis=0, inplace=True)\n",
        "label = ['Positive','Positive','Positive','Positive','Positive','Positive','Positive']\n",
        "Positve_df['Label'] = label\n",
        "Positve_df = Positve_df.explode('Positive')\n",
        "Positve_df.rename(columns = {'Positive':'rel_Claim'}, inplace = True)\n",
        "Positve_df"
      ],
      "metadata": {
        "id": "wsfdDyx32mI4"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge dataFrame "
      ],
      "metadata": {
        "id": "y4k9RLgDAA1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataframe = pd.concat((Negative_df, Positve_df)).sort_index(axis = 0)\n",
        "new_dataframe = new_dataframe.sample(frac = 1)\n",
        "new_dataframe.reset_index(inplace=True)\n",
        "new_dataframe.to_csv('Final_df_EPO.csv', index=False)"
      ],
      "metadata": {
        "id": "FCjOX1mO_6G2"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Final_df_EPO.csv')"
      ],
      "metadata": {
        "id": "fpdU9gxRCZI1"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def textMerge(x):\n",
        "  text = ''\n",
        "  x = eval(x)\n",
        "  for i in x:\n",
        "    for j in i:\n",
        "      text+=i[j]\n",
        "  return text"
      ],
      "metadata": {
        "id": "gxL7tDYoAR_9"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Cited Text'] = df['Cited Text'].apply(lambda x: textMerge(x))"
      ],
      "metadata": {
        "id": "RRM2d0klA_t-"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('Final_df_EPO.csv', index=False)"
      ],
      "metadata": {
        "id": "wMmiaX_rAG_3"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CcHOdapPCpoe",
        "outputId": "404524bf-1f9d-43a7-b9db-e29220550ed0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Cited Text  \\\n",
              "0   [0006]    Bisher sind Anzeigevarianten für Amp...   \n",
              "1   [0007]    Die der vorliegenden Erfindung zugru...   \n",
              "2   [0007]    Die der vorliegenden Erfindung zugru...   \n",
              "3   [0018]    In one or more embodiments, the firs...   \n",
              "4   [0028]    The direct sound calculator 101, the...   \n",
              "..                                                ...   \n",
              "64  [0028]    The direct sound calculator 101, the...   \n",
              "65  [0001]    The present invention relates to a m...   \n",
              "66  [0007]    Die der vorliegenden Erfindung zugru...   \n",
              "67  [0007]    Die der vorliegenden Erfindung zugru...   \n",
              "68  [0006]    Bisher sind Anzeigevarianten für Amp...   \n",
              "\n",
              "                                            rel_Claim     Label  \n",
              "0   14. A computer readable storage medium storing...  Positive  \n",
              "1   4. The method according to claim 3, wherein a ...  Positive  \n",
              "2   13. An electronic device, comprising:\\none or ...  Positive  \n",
              "3   1. An ultra-wide band (UWB) ranging device com...  Positive  \n",
              "4   9. The sound signal processing device accordin...  Negative  \n",
              "..                                                ...       ...  \n",
              "64  11. The sound signal processing device accordi...  Negative  \n",
              "65  9. Method according to claim 1, wherein in the...  Positive  \n",
              "66  15. A computer program comprising instructions...  Positive  \n",
              "67  7. An apparatus for outputting signal light in...  Positive  \n",
              "68  1. A method for outputting signal light inform...  Positive  \n",
              "\n",
              "[69 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01e14fb5-6639-40bb-9415-b9163666fcac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cited Text</th>\n",
              "      <th>rel_Claim</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0006]    Bisher sind Anzeigevarianten für Amp...</td>\n",
              "      <td>14. A computer readable storage medium storing...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0007]    Die der vorliegenden Erfindung zugru...</td>\n",
              "      <td>4. The method according to claim 3, wherein a ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0007]    Die der vorliegenden Erfindung zugru...</td>\n",
              "      <td>13. An electronic device, comprising:\\none or ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0018]    In one or more embodiments, the firs...</td>\n",
              "      <td>1. An ultra-wide band (UWB) ranging device com...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0028]    The direct sound calculator 101, the...</td>\n",
              "      <td>9. The sound signal processing device accordin...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>[0028]    The direct sound calculator 101, the...</td>\n",
              "      <td>11. The sound signal processing device accordi...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>[0001]    The present invention relates to a m...</td>\n",
              "      <td>9. Method according to claim 1, wherein in the...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>[0007]    Die der vorliegenden Erfindung zugru...</td>\n",
              "      <td>15. A computer program comprising instructions...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>[0007]    Die der vorliegenden Erfindung zugru...</td>\n",
              "      <td>7. An apparatus for outputting signal light in...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>[0006]    Bisher sind Anzeigevarianten für Amp...</td>\n",
              "      <td>1. A method for outputting signal light inform...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01e14fb5-6639-40bb-9415-b9163666fcac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01e14fb5-6639-40bb-9415-b9163666fcac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01e14fb5-6639-40bb-9415-b9163666fcac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    }
  ]
}