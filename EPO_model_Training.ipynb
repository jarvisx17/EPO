{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOEQPI7tXMClvmMgOXYhnoD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd1a865794a0487e83aff802d68fb849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_513f0c05335645a28e740b1cf934ac55",
              "IPY_MODEL_6ccd040e6c804e53a5965aa1597b2f1e",
              "IPY_MODEL_04949b899f7f4cdbab2465927dca9401"
            ],
            "layout": "IPY_MODEL_8fc926c036b7483b8f6f04f45ff46b74"
          }
        },
        "513f0c05335645a28e740b1cf934ac55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da15bfb526e04b2f989a82c95a0bf57c",
            "placeholder": "​",
            "style": "IPY_MODEL_39938b59c04b49879d1e31a33b40ccfa",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "6ccd040e6c804e53a5965aa1597b2f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cab6496f548144638dd3964b4f20c627",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8093eea50f814e8e928342572385e06e",
            "value": 28
          }
        },
        "04949b899f7f4cdbab2465927dca9401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84959f29d0204ead9ca6d69a9ef58755",
            "placeholder": "​",
            "style": "IPY_MODEL_6611564bdabe4d6a9210ef41cdc89106",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.91kB/s]"
          }
        },
        "8fc926c036b7483b8f6f04f45ff46b74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da15bfb526e04b2f989a82c95a0bf57c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39938b59c04b49879d1e31a33b40ccfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cab6496f548144638dd3964b4f20c627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8093eea50f814e8e928342572385e06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84959f29d0204ead9ca6d69a9ef58755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6611564bdabe4d6a9210ef41cdc89106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e95d2313b5fa48bbbaa38b20eec3b7bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c34e2bbba914623a8324bc9fa931c36",
              "IPY_MODEL_c3cb13d062364e39b1fa7771cc40daaa",
              "IPY_MODEL_40d74d1a3bf6436a8f003023bf1dead1"
            ],
            "layout": "IPY_MODEL_3c7fe92409ca4b63afa8aea9c544af7e"
          }
        },
        "3c34e2bbba914623a8324bc9fa931c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_212e35ad305c439cb75b3fd8f742f45a",
            "placeholder": "​",
            "style": "IPY_MODEL_2d5cffef0777434493e1cb92c511b35d",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c3cb13d062364e39b1fa7771cc40daaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1f3ba6f886b407a9a3dd90ed54b17e1",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0efd74e64fd4503a0313f074f32f789",
            "value": 570
          }
        },
        "40d74d1a3bf6436a8f003023bf1dead1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e054e5e77b347828f577a9e99d8dc62",
            "placeholder": "​",
            "style": "IPY_MODEL_334f9c005e12408c87dc72795156648a",
            "value": " 570/570 [00:00&lt;00:00, 41.2kB/s]"
          }
        },
        "3c7fe92409ca4b63afa8aea9c544af7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "212e35ad305c439cb75b3fd8f742f45a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d5cffef0777434493e1cb92c511b35d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1f3ba6f886b407a9a3dd90ed54b17e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0efd74e64fd4503a0313f074f32f789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e054e5e77b347828f577a9e99d8dc62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "334f9c005e12408c87dc72795156648a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06b678dadaa94fd699876e8c123b08d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc2f0eedeb234bc183f8fcc2e43a4c79",
              "IPY_MODEL_0180e03390c446f3bac21686e2f0848d",
              "IPY_MODEL_022feec8a0584329ac21a63ba1e10a9f"
            ],
            "layout": "IPY_MODEL_f3380a654f484cefb00f19b1a3b9e331"
          }
        },
        "fc2f0eedeb234bc183f8fcc2e43a4c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9aefa891d79420f8b54c04719440552",
            "placeholder": "​",
            "style": "IPY_MODEL_e8e6f76e93864c8ab38c32aa74144b2a",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "0180e03390c446f3bac21686e2f0848d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45bf4c7298f847ff8ab8ec08e53094ff",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e46b53d6fa1244afac9a1bf042f4e2ff",
            "value": 440473133
          }
        },
        "022feec8a0584329ac21a63ba1e10a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0df38de7940740ebb3aacb30dbd22d47",
            "placeholder": "​",
            "style": "IPY_MODEL_610ffd620442483f9da6accdf4c80efa",
            "value": " 440M/440M [00:05&lt;00:00, 89.1MB/s]"
          }
        },
        "f3380a654f484cefb00f19b1a3b9e331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9aefa891d79420f8b54c04719440552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8e6f76e93864c8ab38c32aa74144b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45bf4c7298f847ff8ab8ec08e53094ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46b53d6fa1244afac9a1bf042f4e2ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0df38de7940740ebb3aacb30dbd22d47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "610ffd620442483f9da6accdf4c80efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarvisx17/EPO/blob/main/EPO_model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers"
      ],
      "metadata": {
        "id": "kGyz1GvKjsmo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "qhx4O50NjQxj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Preprocess the data\n",
        "df = pd.read_csv('/content/Final_df2_EPO.csv')  # Replace 'your_dataset.csv' with your actual dataset file\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "max_length = 512  # Maximum sequence length for input text\n",
        "\n",
        "texts = df['Cited Text'].tolist()\n",
        "claims = df['rel_Claim'].tolist()\n",
        "labels = df['Label'].tolist()"
      ],
      "metadata": {
        "id": "ExaPDMWBpWI_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "cd1a865794a0487e83aff802d68fb849",
            "513f0c05335645a28e740b1cf934ac55",
            "6ccd040e6c804e53a5965aa1597b2f1e",
            "04949b899f7f4cdbab2465927dca9401",
            "8fc926c036b7483b8f6f04f45ff46b74",
            "da15bfb526e04b2f989a82c95a0bf57c",
            "39938b59c04b49879d1e31a33b40ccfa",
            "cab6496f548144638dd3964b4f20c627",
            "8093eea50f814e8e928342572385e06e",
            "84959f29d0204ead9ca6d69a9ef58755",
            "6611564bdabe4d6a9210ef41cdc89106",
            "e95d2313b5fa48bbbaa38b20eec3b7bf",
            "3c34e2bbba914623a8324bc9fa931c36",
            "c3cb13d062364e39b1fa7771cc40daaa",
            "40d74d1a3bf6436a8f003023bf1dead1",
            "3c7fe92409ca4b63afa8aea9c544af7e",
            "212e35ad305c439cb75b3fd8f742f45a",
            "2d5cffef0777434493e1cb92c511b35d",
            "a1f3ba6f886b407a9a3dd90ed54b17e1",
            "e0efd74e64fd4503a0313f074f32f789",
            "2e054e5e77b347828f577a9e99d8dc62",
            "334f9c005e12408c87dc72795156648a"
          ]
        },
        "outputId": "50d4511c-30e6-4266-ac28-c067cc79c490"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd1a865794a0487e83aff802d68fb849"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e95d2313b5fa48bbbaa38b20eec3b7bf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HZhq8TckHd0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nooawjwkUd1",
        "outputId": "b4f3b2e6-6db6-4ab0-a5b0-e52eb324ad1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
              "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text, claim in zip(texts, claims):\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        text,\n",
        "        claim,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ5aK9UUk1n4",
        "outputId": "12173f83-c2be-491a-9cfc-bb293aad047a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Split the data\n",
        "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Load a pre-trained transformer model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# Step 4: Create a classification model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "06b678dadaa94fd699876e8c123b08d8",
            "fc2f0eedeb234bc183f8fcc2e43a4c79",
            "0180e03390c446f3bac21686e2f0848d",
            "022feec8a0584329ac21a63ba1e10a9f",
            "f3380a654f484cefb00f19b1a3b9e331",
            "f9aefa891d79420f8b54c04719440552",
            "e8e6f76e93864c8ab38c32aa74144b2a",
            "45bf4c7298f847ff8ab8ec08e53094ff",
            "e46b53d6fa1244afac9a1bf042f4e2ff",
            "0df38de7940740ebb3aacb30dbd22d47",
            "610ffd620442483f9da6accdf4c80efa"
          ]
        },
        "id": "ULQz4F3-k41r",
        "outputId": "b8122fa5-3636-4d33-ff0b-19306d9254aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06b678dadaa94fd699876e8c123b08d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train the model\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, attention_masks, labels = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    print(f'Epoch {epoch+1}/{epochs} - Average Loss: {avg_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-XEwFUPk7kb",
        "outputId": "35e5363d-77a0-4f3f-c352-69a7179cb238"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Average Loss: 0.5564049035310745\n",
            "Epoch 2/20 - Average Loss: 0.47262194007635117\n",
            "Epoch 3/20 - Average Loss: 0.35150160640478134\n",
            "Epoch 4/20 - Average Loss: 0.25624828413128853\n",
            "Epoch 5/20 - Average Loss: 0.2507883459329605\n",
            "Epoch 6/20 - Average Loss: 0.20128446072340012\n",
            "Epoch 7/20 - Average Loss: 0.143555399030447\n",
            "Epoch 8/20 - Average Loss: 0.11200217436999083\n",
            "Epoch 9/20 - Average Loss: 0.10982909798622131\n",
            "Epoch 10/20 - Average Loss: 0.10579824354499578\n",
            "Epoch 11/20 - Average Loss: 0.08278318960219622\n",
            "Epoch 12/20 - Average Loss: 0.07817942695692182\n",
            "Epoch 13/20 - Average Loss: 0.07560586743056774\n",
            "Epoch 14/20 - Average Loss: 0.07380335219204426\n",
            "Epoch 15/20 - Average Loss: 0.07836930966004729\n",
            "Epoch 16/20 - Average Loss: 0.09409598866477609\n",
            "Epoch 17/20 - Average Loss: 0.09803911484777927\n",
            "Epoch 18/20 - Average Loss: 0.0479310667142272\n",
            "Epoch 19/20 - Average Loss: 0.035560015588998795\n",
            "Epoch 20/20 - Average Loss: 0.03104665270075202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluate the model\n",
        "model.eval()\n",
        "total_predictions, correct_predictions = 0, 0\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    input_ids, attention_masks, labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_masks)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    predicted_labels = torch.argmax(logits, dim=1)\n",
        "    total_predictions += labels.size(0)\n",
        "    correct_predictions += (predicted_labels == labels).sum().item()\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ9_RgxXqjXd",
        "outputId": "df02a3fe-3eb6-404e-ec34-6bc47ec8cd63"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO1DOHSAjFNp",
        "outputId": "bd54b6bb-443b-4550-e17d-8db526fce22e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7857142857142857\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Evaluate the model\n",
        "model.eval()\n",
        "total_predictions, correct_predictions = 0, 0\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    input_ids, attention_masks, labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_masks)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    predicted_labels = torch.argmax(logits, dim=1)\n",
        "    total_predictions += labels.size(0)\n",
        "    correct_predictions += (predicted_labels == labels).sum().item()\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(model, 'model_weights.pth')\n",
        "# Save the model weights\n",
        "torch.save(model.state_dict(), 'model_weights.pth')\n",
        "\n",
        "# Save the entire model (including architecture and optimizer state)\n",
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "id": "0kCDpcUwlc8E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# Load the trained model weights\n",
        "model.load_state_dict(torch.load('model_weights.pth'))  # Replace 'model_weights.pth' with the path to your trained model weights\n",
        "\n",
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Text and claim to be classified\n",
        "text = df.iloc[0][0]\n",
        "claim = df.iloc[0][1]\n",
        "actual = df.iloc[0][2]\n",
        "\n",
        "# Tokenize and encode the input\n",
        "input_ids = tokenizer.encode(text, claim, add_special_tokens=True, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n",
        "input_ids = input_ids.to(device)\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids=input_ids)\n",
        "    logits = outputs.logits\n",
        "    predicted_labels = torch.argmax(logits, dim=1)\n",
        "\n",
        "predicted_label = predicted_labels.item()\n",
        "if predicted_label == 0:\n",
        "    prediction = \"Negative\"\n",
        "else:\n",
        "    prediction = \"Positive\"\n",
        "\n",
        "print(f\"Prediction: {prediction}  \\nActual : {actual}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTv5nJK8lbt_",
        "outputId": "9b12e9fb-ba8c-4e8a-b377-fba932123dbf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Negative  \n",
            "Actual : Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Wise Inference"
      ],
      "metadata": {
        "id": "pAfb7mfeIoiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Data\n",
        "\n",
        "citation_text = '''[0028]    The direct sound calculator 101, the early reflected sound calculator 102, and the late reverberant sound calculator 103 calculate propagation characteristics relating to a direct sound, early reflected sounds, and late reverberant sounds, respectively. More specifically, the direct sound calculator 101 applies a simulation result of propagation characteristics corresponding to a direct sound propagation path of a space to an input signal that is received from the input terminal 115, and allocates resulting signals to plural output lines to which the respective multipliers 106 are connected.[0029]    The early reflected sound calculator 102 applies simulation results of propagation characteristics corresponding to respective propagation paths of early reflected sounds to an input signal that is received from the input terminal 115 via the acoustic characteristics approximation filter 104, and allocates resulting signals to plural output lines to which the respective multipliers 107 are connected.[0030]    The late reverberant sound calculator 103 applies simulation results of propagation characteristics corresponding to respective propagation paths of late reverberant sounds to the input signal that is received from the input terminal 115, and allocates resulting signals to plural output lines to which the non-correlation IR convolution filter 105 is connected.[0044]    Returning to Fig. 3 , the multipliers 106 are disposed downstream of the respective output lines 242 of the direct sound calculator 101. The multipliers 106 multiply audio signals (indicating a direct sound) that are output from the output terminals of the direct sound calculator 101 by particular coefficients specified by the controller 10. The multipliers 107 are disposed downstream of the respective output lines 242 of the early reflected sound calculator 102. The multipliers 107 multiply audio signals (indicating early reflected sounds) that are output from the output terminals of the early reflected sound calculator 102 by particular coefficients specified by the controller 10. The multipliers 108 are disposed downstream of the non-correlation IR convolution filter 105. The multipliers 108 multiply audio signals (indicating late reverberant sounds) that have been subjected to the filter processing of the non-correlation IR convolution filter 105 by particular coefficients specified by the controller 10. The sets of multipliers 106, 107, and 108 have roles of adjusting sound volume balance of a direct sound, early reflected sounds, and late reverberant sounds, respectively, according to the sets of coefficients specified by the controller 10.[0045]    The adders 109 add output audio signals of the multipliers 106 on the output lines 242 to output audio signals of the multipliers 107 on the corresponding output lines 242. That is, the adders 109 have a role of adding direct sounds to early reflected sounds on an output-system-by-output-system basis. The adders 110 add output audio signals of the adders 109 on the output lines 242 to output audio signals of the multipliers 108 on the corresponding output lines 242. That is, the adders 110 have a role of adding direct sounds, early reflected sounds, and late reverberant sounds together on an output-system-by-output-system basis. The adders 110 output, to the output stage speakers 80, output signals obtained by adding reverberant sound signals to the input signal.'''\n",
        "\n",
        "claims = [\n",
        "    \"1. A sound signal processing method comprising:\\nreceiving a sound signal;\\ngenerating an early reflection sound control signal that reproduces an early reflection sound and a reverberant sound control signal that reproduces a reverberant sound from the sound signal;\\ncontrolling a volume of the sound signal and distributing the sound signal to generate a direct sound control signal that reproduces a direct sound; and\\nmixing the direct sound control signal, the early reflection sound control signal, and the reverberant sound control signal to generate an output signal.\",\n",
        "    \"2. The sound signal processing method according to claim 1, further comprising:\\nobtaining an impulse response of an early reflection sound measured in advance in a space and an impulse response of a reverberant sound measured in advance in the space;\\nconvolving the impulse response of the early reflection sound with the sound signal to generate the early reflection sound control signal; and\\nconvolving the impulse response of the reverberant sound with the sound signal to generate the reverberant sound control signal.\",\n",
        "    \"3. The sound signal processing method according to claim 2, wherein the sound signal to be convolved with the impulse response of the reverberant sound is received from an omnidirectional microphone (12A, 12B, 12C).\",\n",
        "    \"4. The sound signal processing method according to any one of claims 1 to 3, wherein receiving the sound signal comprises receiving a line-inputted sound signal.\",\n",
        "    \"5. The sound signal processing method according to any one of claims 1 to 3, wherein receiving the sound signal comprises receiving the sound signal from a microphone disposed on a performer.\",\n",
        "    \"6. The sound signal processing method according to claim 5, wherein\\nthe microphone is a directional microphone (11A, 11B, 11C).\",\n",
        "    \"7. A sound signal processing device comprising:\\na sound signal obtainer (21) that obtains a sound signal;\\nan early reflection sound control signal generator (24A) that generates an early reflection sound control signal that reproduces an early reflection sound from the sound signal;\\na reverberant sound control signal generator (24B) that generates a reverberant sound control signal that reproduces a reverberant sound from the sound signal;\\na direct sound control signal generator (23D) that generates a direct sound control signal that reproduces a direct sound by controlling a volume of the sound signal and distributing the sound signal; and\\nan output signal generator (26) that generates an output signal by mixing the direct sound control signal, the early reflection sound control signal, and the reverberant sound control signal.\",\n",
        "    \"8. The sound signal processing device according to claim 7, further comprising:\\nan impulse response obtainer (151) that obtains an impulse response of an early reflection sound measured in advance in a space and an impulse response of a reverberant sound measured in advance in the space,\\nwherein\\nthe early reflection sound control signal generator (24A) convolves the impulse response of the early reflection sound with the sound signal to generate the early reflection sound control signal; and\\nthe reverberant sound control signal generator (24B) convolves the impulse response of the reverberant sound with the sound signal to generate the reverberant sound control signal.\",\n",
        "    \"9. The sound signal processing device according to claim 8, wherein\\nthe sound signal to be convolved with the impulse response of the reverberant sound is received from an omnidirectional microphone (12A, 12B, 12C).\",\n",
        "    \"10. The sound signal processing device according to any one of claims 7 to 9, wherein\\nthe sound signal obtainer obtains the sound signal by receiving a line-inputted sound signal.\",\n",
        "    \"11. The sound signal processing device according to any one of claims 7 to 9, wherein\\nthe sound signal obtainer obtains the sound signal by receiving the sound signal from a microphone disposed on a performer.\",\n",
        "    \"12. The sound signal processing device according to claim 11, wherein\\nthe microphone is a directional microphone (11A, 11B, 11C).\",\n",
        "    \"13. A sound signal processing program for causing a sound signal processing device to execute processing of:\\nreceiving a sound signal;\\ngenerating an early reflection sound control signal that reproduces an early reflection sound and a reverberant sound control signal that reproduces a reverberant sound from the sound signal;\\ncontrolling a volume of the sound signal and distributing the sound signal to generate a direct sound control signal that reproduces a direct sound; and\\nmixing the direct sound control signal, the early reflection sound control signal, and the reverberant sound control signal to generate an output signal.\"\n",
        "] \n",
        "\n",
        "# Citation details:  4 ['X', 'Y'] ['1,4,7,10,13', '2,3,5,6,8,9,11,12']"
      ],
      "metadata": {
        "id": "v7KCJksYI7I1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_claims = []\n",
        "negative_claims = []\n",
        "for i in claims:\n",
        "  # Text and claim to be classified\n",
        "  text = citation_text\n",
        "  claim = i\n",
        "  # Tokenize and encode the input\n",
        "  input_ids = tokenizer.encode(text, claim, add_special_tokens=True, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n",
        "  input_ids = input_ids.to(device)\n",
        "\n",
        "  # Perform inference\n",
        "  with torch.no_grad():\n",
        "      outputs = model(input_ids=input_ids)\n",
        "      logits = outputs.logits\n",
        "      predicted_labels = torch.argmax(logits, dim=1)\n",
        "\n",
        "  predicted_label = predicted_labels.item()\n",
        "  if predicted_label == 0:\n",
        "      prediction = \"Negative\"\n",
        "      negative_claims.append(i)\n",
        "  else:\n",
        "      prediction = \"Positive\"\n",
        "      positive_claims.append(i)\n",
        "print('\\n\\n')\n",
        "print(\"Positive claims : \")\n",
        "print('\\n')\n",
        "for j in positive_claims:\n",
        "  print(f\"claim :\\n {j}\")\n",
        "print('\\n\\n')\n",
        "print('Negative claims :')\n",
        "print('\\n')\n",
        "for j in negative_claims:\n",
        "  print(f\"claim :\\n {j}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIDyj4ejNaco",
        "outputId": "b07cbeac-e02a-433a-a469-b4b24878f67c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Positive claims : \n",
            "\n",
            "\n",
            "claim :\n",
            " 1. A sound signal processing method comprising:\n",
            "receiving a sound signal;\n",
            "generating an early reflection sound control signal that reproduces an early reflection sound and a reverberant sound control signal that reproduces a reverberant sound from the sound signal;\n",
            "controlling a volume of the sound signal and distributing the sound signal to generate a direct sound control signal that reproduces a direct sound; and\n",
            "mixing the direct sound control signal, the early reflection sound control signal, and the reverberant sound control signal to generate an output signal.\n",
            "claim :\n",
            " 7. A sound signal processing device comprising:\n",
            "a sound signal obtainer (21) that obtains a sound signal;\n",
            "an early reflection sound control signal generator (24A) that generates an early reflection sound control signal that reproduces an early reflection sound from the sound signal;\n",
            "a reverberant sound control signal generator (24B) that generates a reverberant sound control signal that reproduces a reverberant sound from the sound signal;\n",
            "a direct sound control signal generator (23D) that generates a direct sound control signal that reproduces a direct sound by controlling a volume of the sound signal and distributing the sound signal; and\n",
            "an output signal generator (26) that generates an output signal by mixing the direct sound control signal, the early reflection sound control signal, and the reverberant sound control signal.\n",
            "claim :\n",
            " 13. A sound signal processing program for causing a sound signal processing device to execute processing of:\n",
            "receiving a sound signal;\n",
            "generating an early reflection sound control signal that reproduces an early reflection sound and a reverberant sound control signal that reproduces a reverberant sound from the sound signal;\n",
            "controlling a volume of the sound signal and distributing the sound signal to generate a direct sound control signal that reproduces a direct sound; and\n",
            "mixing the direct sound control signal, the early reflection sound control signal, and the reverberant sound control signal to generate an output signal.\n",
            "\n",
            "\n",
            "\n",
            "Negative claims :\n",
            "\n",
            "\n",
            "claim :\n",
            " 2. The sound signal processing method according to claim 1, further comprising:\n",
            "obtaining an impulse response of an early reflection sound measured in advance in a space and an impulse response of a reverberant sound measured in advance in the space;\n",
            "convolving the impulse response of the early reflection sound with the sound signal to generate the early reflection sound control signal; and\n",
            "convolving the impulse response of the reverberant sound with the sound signal to generate the reverberant sound control signal.\n",
            "claim :\n",
            " 3. The sound signal processing method according to claim 2, wherein the sound signal to be convolved with the impulse response of the reverberant sound is received from an omnidirectional microphone (12A, 12B, 12C).\n",
            "claim :\n",
            " 4. The sound signal processing method according to any one of claims 1 to 3, wherein receiving the sound signal comprises receiving a line-inputted sound signal.\n",
            "claim :\n",
            " 5. The sound signal processing method according to any one of claims 1 to 3, wherein receiving the sound signal comprises receiving the sound signal from a microphone disposed on a performer.\n",
            "claim :\n",
            " 6. The sound signal processing method according to claim 5, wherein\n",
            "the microphone is a directional microphone (11A, 11B, 11C).\n",
            "claim :\n",
            " 8. The sound signal processing device according to claim 7, further comprising:\n",
            "an impulse response obtainer (151) that obtains an impulse response of an early reflection sound measured in advance in a space and an impulse response of a reverberant sound measured in advance in the space,\n",
            "wherein\n",
            "the early reflection sound control signal generator (24A) convolves the impulse response of the early reflection sound with the sound signal to generate the early reflection sound control signal; and\n",
            "the reverberant sound control signal generator (24B) convolves the impulse response of the reverberant sound with the sound signal to generate the reverberant sound control signal.\n",
            "claim :\n",
            " 9. The sound signal processing device according to claim 8, wherein\n",
            "the sound signal to be convolved with the impulse response of the reverberant sound is received from an omnidirectional microphone (12A, 12B, 12C).\n",
            "claim :\n",
            " 10. The sound signal processing device according to any one of claims 7 to 9, wherein\n",
            "the sound signal obtainer obtains the sound signal by receiving a line-inputted sound signal.\n",
            "claim :\n",
            " 11. The sound signal processing device according to any one of claims 7 to 9, wherein\n",
            "the sound signal obtainer obtains the sound signal by receiving the sound signal from a microphone disposed on a performer.\n",
            "claim :\n",
            " 12. The sound signal processing device according to claim 11, wherein\n",
            "the microphone is a directional microphone (11A, 11B, 11C).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvxsLLDyNGTv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}